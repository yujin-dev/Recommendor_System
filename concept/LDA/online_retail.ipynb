{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "import gensim.corpora as corpora\n",
    "import gensim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def preprocess(data):\n",
    "    # 사용자 아이디가 없는 데이터 제외\n",
    "    # quantity 음수인 데이터 제외\n",
    "    df = data[~(data['CustomerID'].isnull())&(data['Quantity']>0)]\n",
    "    df['CustomerID'] = df.CustomerID.astype(int)\n",
    "    df['StockCode'] = df['StockCode'].astype(str)\n",
    "    df = df[['InvoiceNo', 'StockCode', 'Quantity', 'CustomerID', 'InvoiceDate']]\n",
    "    df['ym'] = df['InvoiceDate'].apply(lambda x: str(x)[:7])\n",
    "    return df\n",
    "\n",
    "def split_train_test(data):\n",
    "    train_data = data[(data[\"ym\"]>='2011-09')&(data[\"ym\"]<='2011-11')]\n",
    "    test_data = data[(data['ym']=='2011-12')]\n",
    "    return train_data, test_data\n",
    "\n",
    "def train_groupby(train_data, test_data):\n",
    "    train_groupby = train_data.groupby(['CustomerID'])\n",
    "    return train_groupby\n",
    "\n",
    "\n",
    "def make_train_data(data):\n",
    "    doc_list = []\n",
    "    for user_id, user_df in data:\n",
    "        stockcodes = user_df['StockCode'].values.tolist()\n",
    "        doc_list.append(stockcodes)\n",
    "    id2word = corpora.Dictionary(doc_list)\n",
    "    corpus = [id2word.doc2bow(doc) for doc in doc_list]\n",
    "    return id2word, corpus"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def get_precision(X:list, Y:list):\n",
    "    _intersection = set(X).intersection(Y)\n",
    "    return len(_intersection) / len(Y)\n",
    "\n",
    "def get_recall(X:list, Y:list):\n",
    "    _intersection = set(X).intersection(Y)\n",
    "    return len(_intersection) / len(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "path = os.path.join(Path(os.getcwd()).parent, \"data\")\n",
    "online_retail = os.path.join(path, \"online_retail\", \"online_retail.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "from datetime import datetime\n",
    "parse_date = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M\")\n",
    "retail_df = pd.read_csv(online_retail, encoding=\"utf-8\", parse_dates=[\"InvoiceDate\"],\n",
    "                        date_parser=parse_date)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "train_data, test_data = split_train_test(preprocess(retail_df))\n",
    "train_df = train_groupby(train_data, test_data)\n",
    "id2word, corpus = make_train_data(train_df)\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(id2word=id2word, corpus=corpus, num_topics=20, passes=10,\n",
    "                                              per_word_topics=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_5145/1772559933.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CustomerID'] = df.CustomerID.astype(int)\n",
      "/tmp/ipykernel_5145/1772559933.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['StockCode'] = df['StockCode'].astype(str)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### topic별 top 10 아이템 분포"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "topics = ldamodel.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0, '0.012*\"21615\" + 0.012*\"21616\" + 0.012*\"21619\" + 0.011*\"21620\" + 0.011*\"21108\"')\n",
      "(1, '0.040*\"22423\" + 0.039*\"22699\" + 0.037*\"22697\" + 0.033*\"22698\" + 0.025*\"23245\"')\n",
      "(2, '0.057*\"22865\" + 0.056*\"22866\" + 0.047*\"22867\" + 0.046*\"22633\" + 0.042*\"23439\"')\n",
      "(3, '0.026*\"21181\" + 0.026*\"21175\" + 0.025*\"21166\" + 0.024*\"85152\" + 0.021*\"82494L\"')\n",
      "(4, '0.008*\"23355\" + 0.007*\"20727\" + 0.006*\"23300\" + 0.006*\"23321\" + 0.006*\"23356\"')\n",
      "(5, '0.022*\"POST\" + 0.021*\"21212\" + 0.015*\"21080\" + 0.014*\"21213\" + 0.013*\"23293\"')\n",
      "(6, '0.015*\"22750\" + 0.015*\"22749\" + 0.015*\"22144\" + 0.014*\"22568\" + 0.014*\"20971\"')\n",
      "(7, '0.015*\"21232\" + 0.013*\"21231\" + 0.012*\"79321\" + 0.012*\"22993\" + 0.011*\"22720\"')\n",
      "(8, '0.016*\"23351\" + 0.016*\"23354\" + 0.016*\"23349\" + 0.016*\"23353\" + 0.013*\"23350\"')\n",
      "(9, '0.012*\"23321\" + 0.011*\"23322\" + 0.011*\"85123A\" + 0.010*\"22469\" + 0.010*\"22577\"')\n",
      "(10, '0.039*\"21669\" + 0.032*\"21670\" + 0.032*\"21668\" + 0.031*\"23032\" + 0.027*\"21672\"')\n",
      "(11, '0.027*\"22726\" + 0.022*\"22727\" + 0.012*\"22728\" + 0.012*\"22730\" + 0.012*\"22725\"')\n",
      "(12, '0.046*\"23355\" + 0.035*\"22112\" + 0.031*\"22114\" + 0.026*\"22835\" + 0.025*\"23356\"')\n",
      "(13, '0.017*\"23395\" + 0.016*\"23393\" + 0.015*\"23396\" + 0.013*\"84946\" + 0.013*\"23394\"')\n",
      "(14, '0.017*\"22577\" + 0.014*\"22578\" + 0.011*\"22579\" + 0.011*\"21034\" + 0.009*\"47503A\"')\n",
      "(15, '0.015*\"22086\" + 0.013*\"22910\" + 0.011*\"23084\" + 0.009*\"21790\" + 0.008*\"23319\"')\n",
      "(16, '0.032*\"85099B\" + 0.028*\"23203\" + 0.024*\"23209\" + 0.022*\"20725\" + 0.021*\"22382\"')\n",
      "(17, '0.025*\"23309\" + 0.018*\"84992\" + 0.017*\"21975\" + 0.016*\"23308\" + 0.016*\"23307\"')\n",
      "(18, '0.058*\"22998\" + 0.043*\"23005\" + 0.042*\"22996\" + 0.032*\"22197\" + 0.026*\"22999\"')\n",
      "(19, '0.023*\"20992\" + 0.020*\"M\" + 0.014*\"22138\" + 0.014*\"23194\" + 0.013*\"22617\"')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 20개 토픽의 Top 5 아이템 분포"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "stock_to_description = {row[\"StockCode\"]: row[\"Description\"] for _, row in retail_df.iterrows()}\n",
    "for i in range(20):\n",
    "    recommend = ldamodel.show_topic(topicid=i, topn=5)\n",
    "    print(i, [stock_to_description[item] for item, score in recommend])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 ['4 LAVENDER BOTANICAL DINNER CANDLES', '4 PEAR BOTANICAL DINNER CANDLES', '4 VANILLA BOTANICAL CANDLES', 'SET OF 4 ROSE BOTANICAL CANDLES', 'FAIRY CAKE FLANNEL ASSORTED COLOUR']\n",
      "1 ['REGENCY CAKESTAND 3 TIER', 'ROSES REGENCY TEACUP AND SAUCER ', 'GREEN REGENCY TEACUP AND SAUCER', 'PINK REGENCY TEACUP AND SAUCER', 'SET OF 3 REGENCY CAKE TINS']\n",
      "2 ['HAND WARMER OWL DESIGN', 'HAND WARMER SCOTTY DOG DESIGN', 'HAND WARMER BIRD DESIGN', 'HAND WARMER UNION JACK', 'HAND WARMER RED LOVE HEART']\n",
      "3 ['PLEASE ONE PERSON METAL SIGN', 'GIN AND TONIC DIET METAL SIGN', 'COOK WITH WINE METAL SIGN ', 'HAND OVER THE CHOCOLATE   SIGN ', 'WOODEN FRAME ANTIQUE WHITE ']\n",
      "4 ['HOT WATER BOTTLE KEEP CALM', 'LUNCH BAG  BLACK SKULL.', 'GARDENERS KNEELING PAD CUP OF TEA ', 'SMALL WHITE HEART OF WICKER', 'LOVE HOT WATER BOTTLE']\n",
      "5 ['POSTAGE', 'PACK OF 72 RETROSPOT CAKE CASES', 'SET/20 RED RETROSPOT PAPER NAPKINS ', 'PACK OF 72 SKULL CAKE CASES', 'SET OF 12 FAIRY CAKE BAKING CASES']\n",
      "6 ['FELTCRAFT PRINCESS LOLA DOLL', 'FELTCRAFT PRINCESS CHARLOTTE DOLL', 'CHRISTMAS CRAFT LITTLE FRIENDS', 'FELTCRAFT CUSHION OWL', 'PINK BLUE FELT CRAFT TRINKET BOX']\n",
      "7 ['STRAWBERRY CERAMIC TRINKET POT', 'SWEETHEART CERAMIC TRINKET BOX', 'CHILLI LIGHTS', 'SET OF 4 PANTRY JELLY MOULDS', 'SET OF 3 CAKE TINS PANTRY DESIGN ']\n",
      "8 [\"ROLL WRAP 50'S CHRISTMAS\", \"6 GIFT TAGS 50'S CHRISTMAS \", 'ROLL WRAP VINTAGE CHRISTMAS', '6 GIFT TAGS VINTAGE CHRISTMAS ', 'ROLL WRAP VINTAGE SPOT ']\n",
      "9 ['SMALL WHITE HEART OF WICKER', 'LARGE WHITE HEART OF WICKER', 'CREAM HANGING HEART T-LIGHT HOLDER', 'HEART OF WICKER SMALL', 'WOODEN HEART CHRISTMAS SCANDINAVIAN']\n",
      "10 ['BLUE STRIPE CERAMIC DRAWER KNOB', 'BLUE SPOT CERAMIC DRAWER KNOB', 'RED STRIPE CERAMIC DRAWER KNOB', 'DRAWER KNOB CRACKLE GLAZE IVORY', 'WHITE SPOT RED CERAMIC DRAWER KNOB']\n",
      "11 ['ALARM CLOCK BAKELIKE GREEN', 'ALARM CLOCK BAKELIKE RED ', 'ALARM CLOCK BAKELIKE PINK', 'ALARM CLOCK BAKELIKE IVORY', 'ALARM CLOCK BAKELIKE CHOCOLATE']\n",
      "12 ['HOT WATER BOTTLE KEEP CALM', 'CHOCOLATE HOT WATER BOTTLE', 'HOT WATER BOTTLE TEA AND SYMPATHY', 'HOT WATER BOTTLE I AM SO POORLY', 'LOVE HOT WATER BOTTLE']\n",
      "13 ['BELLE JARDINIERE CUSHION COVER', 'HOME SWEET HOME CUSHION COVER ', 'LE JARDIN BOTANIQUE CUSHION COVER', 'ANTIQUE SILVER T-LIGHT GLASS', 'POSTE FRANCE CUSHION COVER']\n",
      "14 ['WOODEN HEART CHRISTMAS SCANDINAVIAN', 'WOODEN STAR CHRISTMAS SCANDINAVIAN', 'WOODEN TREE CHRISTMAS SCANDINAVIAN', 'REX CASH+CARRY JUMBO SHOPPER', nan]\n",
      "15 [\"PAPER CHAIN KIT 50'S CHRISTMAS \", 'PAPER CHAIN KIT VINTAGE CHRISTMAS', 'RABBIT NIGHT LIGHT', 'VINTAGE SNAP CARDS', \"BOX OF 6 MINI 50'S CRACKERS\"]\n",
      "16 ['JUMBO BAG RED RETROSPOT', 'JUMBO BAG VINTAGE DOILY ', 'LUNCH BAG VINTAGE DOILY ', 'LUNCH BAG RED RETROSPOT', 'LUNCH BAG SPACEBOY DESIGN ']\n",
      "17 ['SET OF 60 I LOVE LONDON CAKE CASES ', '72 SWEETHEART FAIRY CAKE CASES', 'PACK OF 60 DINOSAUR CAKE CASES', 'SET OF 60 VINTAGE LEAF CAKE CASES ', 'SET OF 60 PANTRY DESIGN CAKE CASES ']\n",
      "18 ['TRAVEL CARD WALLET KEEP CALM', 'TRAVEL CARD WALLET I LOVE LONDON', 'TRAVEL CARD WALLET VINTAGE TICKET', 'POPCORN HOLDER', 'TRAVEL CARD WALLET VINTAGE LEAF']\n",
      "19 ['JAZZ HEARTS PURSE NOTEBOOK', 'Manual', 'BAKING SET 9 PIECE RETROSPOT ', 'GYMKHANA TREASURE BOOK BOX', 'BAKING SET SPACEBOY DESIGN']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 전체 유저의 토픽 분포"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "user_topic_dist = {}\n",
    "for user_id, user_df in train_df:\n",
    "    document = user_df['StockCode'].values.tolist()\n",
    "    user_topic_dist[user_id] = ldamodel.get_document_topics(id2word.doc2bow(document), minimum_probability=0)\n",
    "print(\"12682번 user 토픽 분포\\n\", user_topic_dist[12682])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12682번 user 토픽 분포\n",
      " [(0, 0.00035469927), (1, 0.00035469927), (2, 0.00035469927), (3, 0.00035469927), (4, 0.00035469927), (5, 0.19515014), (6, 0.03278907), (7, 0.00035469927), (8, 0.00035469927), (9, 0.00035469927), (10, 0.00035469927), (11, 0.00035469927), (12, 0.00035469927), (13, 0.0003546993), (14, 0.00035469927), (15, 0.23734611), (16, 0.50640327), (17, 0.00035469927), (18, 0.022990933), (19, 0.00035469927)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 12682번 유저 토픽 분포에서 가장 확률이 높은 토픽 선택 → Top 20 아이템 추천"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "user_topics = user_topic_dist[12682]\n",
    "user_topics = sorted(user_topics, key=lambda x: (x[1]), reverse=True)\n",
    "user_topic = user_topics[0][0]\n",
    "print('가장 확률이 높은 토픽 : ', user_topic)\n",
    "recommend = ldamodel.show_topic(topicid=user_topic, topn=20)\n",
    "print('Top 20 아이템 추천 : ', [item for item, _ in recommend])\n",
    "relevant = test_data[test_data[\"CustomerID\"]==12682]['StockCode'].unique()\n",
    "print(\"실제 12682번 유저가 데이터에서 선호한 아이템 : \", relevant)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "가장 확률이 높은 토픽 :  16\n",
      "Top 20 아이템 추천 :  ['85099B', '23203', '23209', '20725', '22382', '20727', '23344', '23202', '22383', '22386', '23206', '20728', '23199', '22384', '23581', '20724', '23583', '23201', '23343', '20726']\n",
      "실제 12682번 유저가 데이터에서 선호한 아이템 :  ['20750' '21931' '85099B' '22423' '21242' '21243' '21239' '21240' '23040'\n",
      " '22596' '22456' '48185' '21770' '21977' '21212' '84375' '23163' '84378'\n",
      " '23020' '22966' '23084' '22556' '22551' '22555' '47566' '23192' '22139'\n",
      " '22138' '22467' 'POST']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 유저별 LDAmodel 추천(Top 20) 성능"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import numpy as np\n",
    "\n",
    "train_user_ids = train_data['CustomerID'].unique()\n",
    "test_user_ids = test_data['CustomerID'].unique()\n",
    "\n",
    "topn = 20\n",
    "default_recommend = list(train_data.groupby('StockCode')['Quantity'].count().sort_values(ascending=False)[:topn].index)\n",
    "precisions, recalls = [], []\n",
    "for user_id in test_user_ids:\n",
    "    if user_id in train_user_ids:\n",
    "        user_topics = user_topic_dist[user_id]\n",
    "        user_topics = sorted(user_topics, key = lambda x: (x[1]), reverse=True)\n",
    "        user_topic = user_topics[0][0]\n",
    "        recommend = [item for item, _ in ldamodel.show_topic(topicid=user_topic, topn=topn)]\n",
    "    else:\n",
    "        recommend =default_recommend\n",
    "\n",
    "    relevant = test_data[test_data['CustomerID'] == user_id]['StockCode'].unique()\n",
    "    precisions.append(get_precision(relevant, recommend))\n",
    "    recalls.append(get_recall(relevant, recommend))\n",
    "print(\"Precision@K : \", np.mean(precisions))\n",
    "print(\"Recall@K : \", np.mean(recalls))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision@K :  0.10089430894308944\n",
      "Recall@K :  0.11428890195384434\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "venv_py3.8",
   "display_name": "venv_py3.8",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}