{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "from surprise import KNNBasic, KNNWithMeans, SVD\n",
    "from surprise.model_selection.validation import cross_validate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def make_array(data):\n",
    "    user_item_mtx = data.pivot_table(values=\"rating\", index=\"userId\", columns=\"movieId\").fillna(0)\n",
    "    return user_item_mtx.to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "class MF:\n",
    "    def __init__(self, R, K, learning_rate, regularization, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        self.iterations = iterations\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_rmse(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_ratings(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_R_hat(self):\n",
    "        pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "class SGD(MF):\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        self.P = np.random.normal(scale=1. / self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1. / self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        self.bias_u = np.zeros(self.num_users)\n",
    "        self.bias_i = np.zeros(self.num_items)\n",
    "        self.bias = np.mean(self.R[np.where(self.R != 0)])\n",
    "        self.train_data = [\n",
    "            (u, i, self.R[u, i])\n",
    "            for u in range(self.num_users)\n",
    "            for i in range(self.num_items)\n",
    "            if self.R[u, i] > 0]\n",
    "\n",
    "        training_result=[]\n",
    "        for epoch in range(self.iterations):\n",
    "            np.random.shuffle(self.train_data)\n",
    "            self.update_sgd()\n",
    "            rmse = self.get_rmse()\n",
    "            training_result.append([epoch+1, rmse])\n",
    "        self.result = pd.DataFrame(training_result, columns=[\"epoch\", \"rmse\"])\n",
    "\n",
    "\n",
    "    def update_sgd(self):\n",
    "\n",
    "        for u, i, true_r in self.train_data:\n",
    "            prediction = self.predict_ratings(u, i)\n",
    "            err = (true_r - prediction)\n",
    "            # 파라미터 업데이트\n",
    "            self.bias_u[u] += self.learning_rate * (err - self.regularization * self.bias_u[u])\n",
    "            self.bias_i[i] += self.learning_rate * (err - self.regularization * self.bias_i[i])\n",
    "            self.P[u, :] += self.learning_rate * (err * self.Q[i, :] - self.regularization * self.P[u, :])\n",
    "            self.Q[i, :] += self.learning_rate * (err * self.P[u, :] - self.regularization * self.Q[i, :])\n",
    "\n",
    "    def get_rmse(self):\n",
    "        users, items = self.R.nonzero()\n",
    "        predicted_r = self.get_R_hat()\n",
    "        error = []\n",
    "        for x, y in zip(users, items):\n",
    "            error.append(pow(self.R[x, y] - predicted_r[x, y], 2))\n",
    "        rmse = np.sqrt(np.asarray(error).mean())\n",
    "        return rmse\n",
    "\n",
    "    def predict_ratings(self, user, item):\n",
    "        prediction = self.bias + self.bias_u[user] + self.bias_i[item] + self.P[user, :].dot(self.Q[item, :].T)\n",
    "        return prediction\n",
    "\n",
    "    def get_R_hat(self):\n",
    "        return self.bias + self.bias_u[:, np.newaxis] + self.bias_i[np.newaxis, :] + self.P.dot(self.Q.T)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "class ALS(MF):\n",
    "\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1. / self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1. / self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        training_result=[]\n",
    "        for epoch in range(self.iterations):\n",
    "            for u, Ru in enumerate(self.R):\n",
    "                self.P[u] = self.user_latent(u)\n",
    "            for i, Ri in enumerate(self.R.T):\n",
    "                self.Q[i] = self.item_latent(i)\n",
    "\n",
    "            rmse = self.get_rmse()\n",
    "            training_result.append((epoch, rmse))\n",
    "\n",
    "    def user_latent(self, user):\n",
    "        return np.linalg.solve(np.dot(self.P.T, self.P) + self.regularization * np.eye(self.K),\n",
    "                               np.dot(self.P.T, self.R[user].T)).T\n",
    "\n",
    "    def item_latent(self, item):\n",
    "        return np.linalg.solve(np.dot(self.Q.T, self.Q) + self.regularization * np.eye(self.K),\n",
    "                               np.dot(self.Q.T, self.R[:, item]))\n",
    "\n",
    "    def get_rmse(self):\n",
    "        xi, yi = self.R.nonzero()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self.R[x, y] - self.predict_ratings(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "    def predict_ratings(self, item, user):\n",
    "        return self.P[item, :].dot(self.Q[user, :].T)\n",
    "\n",
    "    def get_R_hat(self):\n",
    "        return self.P.dot(self.Q.T)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = os.path.join(Path(os.getcwd()).parent, \"data\")\n",
    "ratings = os.path.join(path, \"ml-latest-small\", \"ratings.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "ratings_df = pd.read_csv(ratings, encoding='utf-8')\n",
    "ratings_mtx = make_array(ratings_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(x, y):\n",
    "    plt.figure(figsize=((8,4)))\n",
    "    plt.plot(x, y)\n",
    "    plt.xticks(x, y)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.grid(axis=\"y\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SGD 학습"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "sgd = SGD(ratings_mtx)\n",
    "sgd.train()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'K', 'learning_rate', 'regularization', and 'iterations'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5659/3812148611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'K', 'learning_rate', 'regularization', and 'iterations'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = sgd.result.epoch.values + 1\n",
    "y = sgd.result.rmse.values\n",
    "plot(x, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ALS 학습"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "als = ALS(ratings_mtx)\n",
    "als.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = als.result.epoch.values + 1\n",
    "y = als.result.rmse.values\n",
    "plot(x, y)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "venv_py3.8",
   "display_name": "venv_py3.8",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}